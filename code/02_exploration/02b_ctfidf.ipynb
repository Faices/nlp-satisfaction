{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"961ed1d8c3ae4172b4327b6f82560d6c","deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":1},"deepnote_cell_type":"markdown"},"source":["# cTF-IDF"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Creates TF-IDF top 10 keywords for different timeframes (Year, Quarter, Season, Month) and different groups (Age,Gender,Fahrzweck,Klasse....)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-05-24 07:30:13.655128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import sys\n","import os\n","sys.path.append(os.path.abspath('../')) ## needed to import the function.py file\n","\n","from functions import *\n","import pandas as pd\n","import plotly.express as px\n","import plotly.io as pio\n","import spacy\n","import xlsxwriter\n","\n","# nltk.download('averaged_perceptron_tagger')\n","# nltk.download('punkt')\n","# nltk.download('stopwords')\n","#!python -m spacy download de_core_news_lg\n","## download nlp language package\n","\n","# Load the German model\n","nlp = spacy.load(\"de_core_news_lg\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import scipy.sparse as sp\n","\n","from sklearn.preprocessing import normalize\n","from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n","\n","\n","class CTFIDFVectorizer(TfidfTransformer):\n","    def __init__(self, *args, **kwargs):\n","        super(CTFIDFVectorizer, self).__init__(*args, **kwargs)\n","\n","    def fit(self, X: sp.csr_matrix, n_samples: int):\n","        \"\"\"Learn the idf vector (global term weights) \"\"\"\n","        _, n_features = X.shape\n","        df = np.squeeze(np.asarray(X.sum(axis=0)))\n","        idf = np.log(n_samples / df)\n","        self._idf_diag = sp.diags(idf, offsets=0,\n","                                  shape=(n_features, n_features),\n","                                  format='csr',\n","                                  dtype=np.float64)\n","        return self\n","\n","    def transform(self, X: sp.csr_matrix) -> sp.csr_matrix:\n","        \"\"\"Transform a count-based matrix to c-TF-IDF \"\"\"\n","        X = X * self._idf_diag\n","        X = normalize(X, axis=1, norm='l1', copy=False)\n","        return X\n","    \n","# Credits: https://www.maartengrootendorst.com/blog/ctfidf/\n","\n","\n","# Get data\n","from sklearn.datasets import fetch_20newsgroups\n","newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n","\n","# Create documents per label\n","docs = pd.DataFrame({'Document': newsgroups.data, 'Class': newsgroups.target})\n","docs_per_class = docs.groupby(['Class'], as_index=False).agg({'Document': ' '.join})\n","\n","# Create c-TF-IDF\n","count = CountVectorizer().fit_transform(docs_per_class.Document)\n","ctfidf = CTFIDFVectorizer().fit_transform(count, n_samples=len(docs))\n","\n","\n","# Create bag of words\n","count_vectorizer = CountVectorizer().fit(docs_per_class.Document)\n","count = count_vectorizer.transform(docs_per_class.Document)\n","words = count_vectorizer.get_feature_names_out()\n","\n","# Extract top 10 words per class\n","ctfidf = CTFIDFVectorizer().fit_transform(count, n_samples=len(docs)).toarray()\n","words_per_class = {newsgroups.target_names[label]: [words[index] for index in ctfidf[label].argsort()[-10:]] \n","                   for label in docs_per_class.Class}\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Load Data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["## Import dataframe for overview with all Surveys from 2019-2022\n","filelocation = '../../data/DataClean'\n","df = pd.read_feather(filelocation)\n","\n","## Import textbased dataframe with all Surveys from 2019-2022 with text comments and prerocessed columns\n","filelocation = '../../data/DataText'\n","df_text = pd.read_feather(filelocation)\n","\n","## load config file\n","config = pd.read_excel('../../config/config.xlsx',sheet_name='fragecodes')\n","invites_month = pd.read_excel('../../config/config.xlsx',sheet_name='invites')"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import scipy.sparse as sp\n","\n","from sklearn.preprocessing import normalize\n","from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n","\n","\n","class CTFIDFVectorizer(TfidfTransformer):\n","    def __init__(self, *args, **kwargs):\n","        super(CTFIDFVectorizer, self).__init__(*args, **kwargs)\n","\n","    def fit(self, X: sp.csr_matrix, n_samples: int):\n","        \"\"\"Learn the idf vector (global term weights) \"\"\"\n","        _, n_features = X.shape\n","        df = np.squeeze(np.asarray(X.sum(axis=0)))\n","        idf = np.log(n_samples / df)\n","        self._idf_diag = sp.diags(idf, offsets=0,\n","                                  shape=(n_features, n_features),\n","                                  format='csr',\n","                                  dtype=np.float64)\n","        return self\n","\n","    def transform(self, X: sp.csr_matrix) -> sp.csr_matrix:\n","        \"\"\"Transform a count-based matrix to c-TF-IDF \"\"\"\n","        X = X * self._idf_diag\n","        X = normalize(X, axis=1, norm='l1', copy=False)\n","        return X\n","\n","\n","def extract_top_words_per_group(df, text_column, group_column):\n","    \"\"\"Extract top 10 words per group from a DataFrame with comments and group information.\"\"\"\n","    # Create documents per group\n","    docs_per_group = df.groupby([group_column], as_index=False).agg({text_column: ' '.join})\n","\n","    # Create c-TF-IDF\n","    count_vectorizer = CountVectorizer().fit(docs_per_group[text_column])\n","    count = count_vectorizer.transform(docs_per_group[text_column])\n","    ctfidf = CTFIDFVectorizer().fit_transform(count, n_samples=len(df))\n","\n","    # Create bag of words\n","    words = count_vectorizer.get_feature_names_out()\n","\n","    # Extract top 10 words per group\n","    ctfidf = CTFIDFVectorizer().fit_transform(count, n_samples=len(df)).toarray()\n","    words_per_group = {group: [words[index] for index in ctfidf[i].argsort()[-10:]] for i, group in enumerate(docs_per_group[group_column])}\n","\n","    return words_per_group"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['participant_id', 'u_date', 'year', 'month', 'quarter', 'yearmonth',\n","       'yearquarter', 'season', 'yearseason', 'Kommentar', 'wime_personal',\n","       'wime_komfort', 'wime_sauberkeit', 'wime_puenktlich',\n","       'wime_platzangebot', 'wime_gesamtzuf', 'wime_preis_leistung',\n","       'wime_fahrplan', 'wime_oes_fahrt', 'S_sprache', 'S_alter', 'S_sex',\n","       'S_wohnsitz', 'u_klassencode', 'S_AB3_HTA', 'R_anschluss', 'R_stoerung',\n","       'device_type', 'dispcode', 'u_ticket', 'u_fahrausweis', 'u_preis',\n","       'R_zweck', 'ft_abfahrt', 'ft_ankunft', 'ft_startort_uic', 'ft_tu',\n","       'ft_vm', 'ft_vm_kurz', 'ft_zielort_uic', 'fg_abfahrt', 'fg_ankunft',\n","       'fg_startort_uic', 'fg_zielort_uic', 'fg_startort', 'fg_zielort',\n","       'ft_startort', 'ft_zielort', 'Kommentar_Character', 'Kommentar_Tokens',\n","       'Kommentar_Types', 'Kommentar_TTR', 'text_preprocessed',\n","       'text_preprocessed_tokenized', 'lemmatized', 'nouns', 'adjectives',\n","       'verbs', 'nouns_adjectives_and_verbs'],\n","      dtype='object')"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["df_text.columns"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"data":{"text/plain":["{'2019Q1': ['ticket',\n","  'werden',\n","  'strecke',\n","  'ist',\n","  'verbindung',\n","  'fahrt',\n","  'züge',\n","  'klasse',\n","  'app',\n","  'zug'],\n"," '2019Q2': ['ticket',\n","  'wagen',\n","  'ist',\n","  'strecke',\n","  'werden',\n","  'züge',\n","  'fahrt',\n","  'klasse',\n","  'app',\n","  'zug'],\n"," '2019Q3': ['werden',\n","  'ticket',\n","  'fahrt',\n","  'ist',\n","  'wagen',\n","  'strecke',\n","  'klasse',\n","  'züge',\n","  'app',\n","  'zug'],\n"," '2019Q4': ['verbindung',\n","  'wagen',\n","  'strecke',\n","  'minuten',\n","  'fahrt',\n","  'verspätung',\n","  'klasse',\n","  'züge',\n","  'app',\n","  'zug'],\n"," '2020Q1': ['ist',\n","  'verbindung',\n","  'klasse',\n","  'ticket',\n","  'strecke',\n","  'fahrt',\n","  'züge',\n","  'verspätung',\n","  'app',\n","  'zug'],\n"," '2020Q2': ['verbindung',\n","  'fahrt',\n","  'züge',\n","  'tragen',\n","  'öv',\n","  'maske',\n","  'app',\n","  'corona',\n","  'zug',\n","  'maskenpflicht'],\n"," '2020Q3': ['velo',\n","  'werden',\n","  'ticket',\n","  'verbindung',\n","  'fahrt',\n","  'ist',\n","  'maske',\n","  'app',\n","  'maskenpflicht',\n","  'zug'],\n"," '2020Q4': ['maskenpflicht',\n","  'werden',\n","  'züge',\n","  'klasse',\n","  'ist',\n","  'fahrt',\n","  'app',\n","  'maske',\n","  'corona',\n","  'zug'],\n"," '2021Q1': ['leute',\n","  'klasse',\n","  'zügen',\n","  'app',\n","  'fahrt',\n","  'ist',\n","  'züge',\n","  'maske',\n","  'corona',\n","  'zug'],\n"," '2021Q2': ['strecke',\n","  'fahrt',\n","  'ist',\n","  'zügen',\n","  'velo',\n","  'werden',\n","  'züge',\n","  'klasse',\n","  'app',\n","  'zug'],\n"," '2021Q3': ['maskenpflicht',\n","  'velo',\n","  'ist',\n","  'zügen',\n","  'wagen',\n","  'werden',\n","  'züge',\n","  'app',\n","  'klasse',\n","  'zug'],\n"," '2021Q4': ['fahrt',\n","  'leute',\n","  'werden',\n","  'strecke',\n","  'ist',\n","  'maskenpflicht',\n","  'klasse',\n","  'züge',\n","  'maske',\n","  'zug'],\n"," '2022Q1': ['umsteigen',\n","  'fahrt',\n","  'strecke',\n","  'maske',\n","  'zügen',\n","  'züge',\n","  'ist',\n","  'maskenpflicht',\n","  'klasse',\n","  'zug'],\n"," '2022Q2': ['verbindung',\n","  'umsteigen',\n","  'werden',\n","  'app',\n","  'ist',\n","  'strecke',\n","  'wagen',\n","  'klasse',\n","  'züge',\n","  'zug'],\n"," '2022Q3': ['strecke',\n","  'ist',\n","  'zügen',\n","  'fahrt',\n","  'werden',\n","  'app',\n","  'wagen',\n","  'züge',\n","  'klasse',\n","  'zug'],\n"," '2022Q4': ['verspätung',\n","  'umsteigen',\n","  'fahrt',\n","  'ist',\n","  'zügen',\n","  'wagen',\n","  'app',\n","  'züge',\n","  'klasse',\n","  'zug']}"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["extract_top_words_per_group(df=df_text, text_column='text_preprocessed', group_column=\"yearquarter\")"]}],"metadata":{"deepnote":{},"deepnote_app_layout":"article","deepnote_execution_queue":[],"deepnote_notebook_id":"de85da757e60432eac612d1b5bb81bbe","kernelspec":{"display_name":"nlp","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"vscode":{"interpreter":{"hash":"2c54f9282dd36543c8181ef7676bc28d81677c039b129753722332dc3d171a18"}}},"nbformat":4,"nbformat_minor":0}
