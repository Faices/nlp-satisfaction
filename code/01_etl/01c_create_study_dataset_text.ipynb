{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.124351582\n",
      "64648\n",
      "Duration:  379.64587565700003\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../')) ## needed to import the function.py file\n",
    "\n",
    "import pandas as pd\n",
    "from functions import *\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "print(start)\n",
    "\n",
    "## Import dataframe\n",
    "filelocation = '../../data/DataClean'\n",
    "df = pd.read_feather(filelocation)\n",
    "\n",
    "###### Stopword list creation #########\n",
    "\n",
    "# import custom stopwords list\n",
    "customstopwords = pd.read_excel('../../config/customstopwords.xlsx')\n",
    "customstopwords = customstopwords['stopword'].tolist()\n",
    "\n",
    "# Also add ortsnamen to the stoplist because we have them in the metadata and dont want them in the comments\n",
    "orte = [x.lower() for x in set(df.ft_startort.tolist()) if x == x and x.lower() != '']\n",
    "\n",
    "# Create the list of locations\n",
    "for location in df.ft_startort.tolist():\n",
    "    # Check if the value is a string\n",
    "    if isinstance(location, str):\n",
    "        # Convert to lowercase and remove 'Zug'\n",
    "        location = location.lower()\n",
    "        if location == 'zug':\n",
    "            continue\n",
    "        \n",
    "        # Split the location into tokens if it contains whitespace\n",
    "        tokens = location.split()\n",
    "        \n",
    "        # Add each token to the list individually\n",
    "        for token in tokens:\n",
    "            # Skip any token that is in the stoplist\n",
    "            if token in orte:\n",
    "                continue\n",
    "            # Remove any commas from the end of the token\n",
    "            token = token.rstrip(',')\n",
    "            orte.append(token)\n",
    "    \n",
    "# Remove duplicates from the list\n",
    "orte = list(set(orte))\n",
    "\n",
    "orte.remove(\"zug\")\n",
    "\n",
    "# extend the stopword list with the ortsnamen\n",
    "customstopwords.extend(orte)\n",
    "\n",
    "## Keep only surveys with filled out \"Kommentar\"\n",
    "df_text = df.dropna(subset=[\"Kommentar\"])\n",
    "\n",
    "#df_text = df_text.head(2000)\n",
    "print(len(df_text))\n",
    "\n",
    "df_text = df_text[df_text.Kommentar.apply(lambda x: len(str(x))>=3)] # min 3 characters for valid comment\n",
    "df_text.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "## Add basic text features\n",
    "df_text[\"Kommentar\"] = remove_redundant_whitespaces(df_text[\"Kommentar\"]) #note: imported function \"remove_redundant_whitespaces\"\n",
    "df_text = add_basic_textfeatures(df_text,\"Kommentar\")\n",
    "\n",
    "## Preprocess text\n",
    "#preprocess_text(df_text, 'Kommentar', locations=didok)\n",
    "preprocess_text(df_text, 'Kommentar', custom_stopwords=customstopwords)\n",
    "\n",
    "\n",
    "# Add Additional data columns for better slicing\n",
    "add_date_columns(df_text, 'u_date')\n",
    "\n",
    "# Sort dataframe by date (newest first)\n",
    "df_text = df_text.sort_values(\"u_date\",ascending=False)\n",
    "\n",
    "\n",
    "############## Export ############## \n",
    "df_text = df_text.reset_index(drop=True)\n",
    "df_text.to_feather('../../data/DataText') # store data in feather file\n",
    "\n",
    "end = timeit.default_timer()\n",
    "print(\"Duration: \",end-start)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c54f9282dd36543c8181ef7676bc28d81677c039b129753722332dc3d171a18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
